{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diversity(lst):\n",
    "    # Compute the average cosine similarity between all pairs of sentences in the list\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "    embeddings = model.encode(lst)\n",
    "    sim = np.inner(embeddings, embeddings)\n",
    "    return np.mean(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_diversity(filenanme):\n",
    "\n",
    "    df = pd.read_csv(filenanme)\n",
    "    df_train = df[df[\"info\"] ==\"train\"]\n",
    "    df_test = df[df[\"info\"] ==\"test\"]\n",
    "\n",
    "    train_diversity = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        train_diversity.append(compute_diversity(list(row)[3:13]))\n",
    "    test_diversity = []\n",
    "    for _, row in df_test.iterrows():\n",
    "        test_diversity.append(compute_diversity(list(row)[3:13]))\n",
    "    train_diversity = 1 - np.mean(train_diversity)\n",
    "    test_diversity = 1 - np.mean(test_diversity)\n",
    "    print(\"train diversity: \", train_diversity, \"test diversity: \", test_diversity)\n",
    "    return train_diversity, test_diversity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1236b3aacbb49b586903e86e049dc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10578ffcbd224934be4821ceb19fde66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e6362779a54d3fba69324538686adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44167d05b734d209a57b3bf8656802b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/y/g/yguo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47b2798b246458a8dce1c042b56f114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f869a21c2219428e984da817973452d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418b7a1e5f6d48b895975ddd1c8ca755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bbfe839d0e42dc8e15c8e6eef827f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6bb4f2c6394fb0ae7aa366b5916fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46401b39b0ee432fbd3a9a593918569d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e539c9b81e84319b2e007199f052ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/y/g/yguo/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.7147020101547241 test diversity:  0.7057546377182007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7147020101547241, 0.7057546377182007)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_diversity(\"dpo_gpto_400_parsed_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'range'"
     ]
    }
   ],
   "source": [
    "np.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_gpto_diversity(filenanme):\n",
    "    \n",
    "    df = pd.read_csv(filenanme)\n",
    "    df_train = df[df[\"info\"] ==\"train\"]\n",
    "    df_test = df[df[\"info\"] ==\"test\"]\n",
    "\n",
    "    train_diversity = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        train_diversity.append(compute_diversity(list(row)[0:13]))\n",
    "    test_diversity = []\n",
    "    for _, row in df_test.iterrows():\n",
    "        test_diversity.append(compute_diversity(list(row)[3:13]))\n",
    "    train_diversity = 1 - np.mean(train_diversity)\n",
    "    test_diversity = 1 - np.mean(test_diversity)\n",
    "    print(\"train diversity: \", train_diversity, \"test diversity: \", test_diversity)\n",
    "    return train_diversity, test_diversity  \n",
    "\n",
    "compute_overall_gpto_diversity(\"gpto_cap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_overall_diversity(\"dpo_gpto_40_parsed_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.5858057737350464 test diversity:  0.5407741665840149\n"
     ]
    }
   ],
   "source": [
    "results = compute_overall_diversity(\"sft_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.5794702470302582 test diversity:  0.5424542129039764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5794702470302582, 0.5424542129039764)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_diversity(\"sft_top1000_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.488442063331604 test diversity:  0.4799564480781555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.488442063331604, 0.4799564480781555)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_diversity(\"sft_top100_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.5365310311317444 test diversity:  0.5353531241416931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5365310311317444, 0.5353531241416931)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_diversity(\"sft_dpo_results.csv\") # DPO trained on Contest 711 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train diversity:  0.6438504159450531 test diversity:  0.5977967381477356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6438504159450531, 0.5977967381477356)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_overall_diversity(\"dpo_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo 100 i iter:\n",
      "train diversity:  0.5907401144504547 test diversity:  0.5666814148426056\n",
      "dpo 200 i iter:\n",
      "train diversity:  0.6341615617275238 test diversity:  0.6147825419902802\n",
      "dpo 300 i iter:\n",
      "train diversity:  0.6385546922683716 test diversity:  0.6277735233306885\n",
      "dpo 400 i iter:\n",
      "train diversity:  0.6230852007865906 test diversity:  0.6135237812995911\n",
      "dpo 500 i iter:\n",
      "train diversity:  0.6277709305286407 test diversity:  0.6222366392612457\n",
      "dpo 600 i iter:\n",
      "train diversity:  0.6237146556377411 test diversity:  0.6169854998588562\n",
      "dpo 700 i iter:\n",
      "train diversity:  0.6167405843734741 test diversity:  0.5888241529464722\n",
      "dpo 800 i iter:\n",
      "train diversity:  0.6134612262248993 test diversity:  0.5922105610370636\n",
      "dpo 900 i iter:\n",
      "train diversity:  0.6159301996231079 test diversity:  0.5834469199180603\n",
      "dpo 1000 i iter:\n",
      "train diversity:  0.6249347925186157 test diversity:  0.621736615896225\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,1001, 100): \n",
    "    print(\"dpo {} i iter:\".format(i)) \n",
    "    compute_overall_diversity(\"dpo_results_ckpt{}.csv\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unique_words(sent):\n",
    "    return  set([''.join(c for c in s if c.isalpha()) for s in sent.split()])\n",
    "\n",
    "def compute_dict_diversity(lst):\n",
    "    jaccard_indices = []  \n",
    "    lsts = [compute_unique_words(s) for s in lst]\n",
    "    for i in lsts:\n",
    "        for j in lsts: \n",
    "            if i != j:\n",
    "                jaccard_indices.append(len(i.intersection(j))/len(i.union(j)))\n",
    "    return np.mean(jaccard_indices)\n",
    "            \n",
    "def compute_overall_dict_diversity(filenanme):\n",
    "    \n",
    "    df = pd.read_csv(filenanme)\n",
    "    df_train = df[df[\"info\"] ==\"train\"]\n",
    "    df_test = df[df[\"info\"] ==\"test\"]\n",
    "\n",
    "    train_diversity = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        train_diversity.append(compute_dict_diversity(list(row)[3:8]))\n",
    "    test_diversity = []\n",
    "    for _, row in df_test.iterrows():\n",
    "        test_diversity.append(compute_dict_diversity(list(row)[3:8]))\n",
    "    train_diversity = 1 - np.mean(train_diversity)\n",
    "    test_diversity = 1 - np.mean(test_diversity)\n",
    "    print(\"train diversity: \", train_diversity, \"test diversity: \", test_diversity)\n",
    "    return train_diversity, test_diversity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpo 100 i iter:\n",
      "train diversity:  0.9414171534385013 test diversity:  0.9318706769466559\n",
      "dpo 200 i iter:\n",
      "train diversity:  0.9504627438080477 test diversity:  0.9435193475156249\n",
      "dpo 300 i iter:\n",
      "train diversity:  0.9491013504564905 test diversity:  0.9438309805954141\n",
      "dpo 400 i iter:\n",
      "train diversity:  0.9431267781475152 test diversity:  0.9429968519239856\n",
      "dpo 500 i iter:\n",
      "train diversity:  0.944726184579757 test diversity:  0.9453017977636887\n",
      "dpo 600 i iter:\n",
      "train diversity:  0.9383937718926292 test diversity:  0.9381115470697334\n",
      "dpo 700 i iter:\n",
      "train diversity:  0.9460554366571772 test diversity:  0.9387151411509401\n",
      "dpo 800 i iter:\n",
      "train diversity:  0.9475344778698822 test diversity:  0.9393691957192183\n",
      "dpo 900 i iter:\n",
      "train diversity:  0.9460287621768707 test diversity:  0.9435984006519336\n",
      "dpo 1000 i iter:\n",
      "train diversity:  0.9426759985894563 test diversity:  0.9484276327745458\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,1001, 100): \n",
    "    print(\"dpo {} i iter:\".format(i)) \n",
    "    compute_overall_dict_diversity(\"dpo_results_ckpt{}.csv\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
