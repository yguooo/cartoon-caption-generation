import pandas as pd
import base64
from openai import OpenAI
import requests
import time
import os
from tqdm import tqdm
import pickle
from rank import compute_accuracy, recalibrate

with open("/Users/chenjiayi/Desktop/humor/contest_num_for_eval", "rb") as file:
        contest_num_for_eval = pickle.load(file) # a list of contest numbers 
# datasets downloaded from hugging face
df_parquet1 = pd.read_parquet("/Users/chenjiayi/Desktop/humor/parquet/train-00000-of-00002.parquet")
df_parquet2 = pd.read_parquet("/Users/chenjiayi/Desktop/humor/parquet/validation-00000-of-00001.parquet")
df_parquet3 = pd.read_parquet("/Users/chenjiayi/Desktop/humor/parquet/test-00000-of-00001.parquet")
df_parquet = pd.concat([df_parquet1, df_parquet2, df_parquet3], ignore_index=True)             

def prepare(Overall = False, BestPick = False, df_parquet = df_parquet,
            contest_list = contest_num_for_eval, folder_path = '/Users/chenjiayi/Desktop/humor/caption-contest-data/summaries'):
    '''
    prepare necessary variables for evaluation of captions generated by various language models
    Overall, BestPick: compare groups of ten captions from different sources, such as human submissions from different ranking levels, or captions generated by different language models
    contest_list: a list of contest numbers to be evaluated
    folder_path: path of caption contest data
    '''
    human_captions_top = []
    human_captions_200 = []
    human_captions_1k = []
    human_captions_median = []
    no_duplicate = []
    for cnum in contest_list: # extract 4 groups of human contestant entries at top10, #200-#209, #1000-#1009 and contestant median
        for filename in os.listdir(folder_path):
            num = int(filename.split('.')[0][:3])
            if num == cnum and num not in no_duplicate:
                no_duplicate.append(num)
                file_path = os.path.join(folder_path, filename)
                df = pd.read_csv(file_path)
                captions_top = ""
                for i in range(10):
                    if i == 0:
                        captions_top += f"{i+1}.\n"
                        captions_top += df["caption"][i]
                    else:
                        captions_top += f"\n{i+1}.\n"
                        captions_top += df["caption"][i]
                human_captions_top.append(captions_top)

                captions_200 = ""
                for i in range(200,210):
                    if i == 200:
                        captions_200 += f"{i-199}.\n"
                        captions_200 += df["caption"][i]
                    else:
                        captions_200 += f"\n{i-199}.\n"
                        captions_200 += df["caption"][i]
                human_captions_200.append(captions_200)

                captions_1k = ""
                for i in range(1000,1010):
                    if i == 1000:
                        captions_1k += f"{i-999}.\n"
                        captions_1k += df["caption"][i]
                    else:
                        captions_1k += f"\n{i-999}.\n"
                        captions_1k += df["caption"][i]
                human_captions_1k.append(captions_1k)

                captions_median = ""
                start, end = len(df)//2 - 5, len(df)//2 + 5
                for i in range(start, end):
                    if i == start:
                        captions_median += f"{i-start+1}.\n"
                        captions_median += df["caption"][i]
                    else:
                        captions_median += f"\n{i-start+1}.\n"
                        captions_median += df["caption"][i]
                human_captions_median.append(captions_median)
    if Overall: # extract descriptions from Hessel et al. corresponding to contest numbers in contest_list
        descriptions = []
        for i in contest_list:
            d = list(df_parquet[df_parquet['contest_number'] == int(i)]['image_description'])[0]
            dud = list(df_parquet[df_parquet['contest_number'] == int(i)]['image_uncanny_description'])[0]
            descriptions.append([d,dud])
        return descriptions, human_captions_top, human_captions_200, human_captions_1k, human_captions_median
    elif BestPick: # extract images from Hessel et al. corresponding to contest numbers in contest_list
        img = []
        for i in contest_list:
            image_bytes = list(df_parquet[df_parquet['contest_number'] == int(i)]['image.bytes'])[0]
            base64_image = base64.b64encode(image_bytes).decode()
            img.append(base64_image)
        return img, human_captions_top, human_captions_200, human_captions_1k, human_captions_median
    

class Evaluation:
    def __init__(self, Overall = False, BestPick = False, 
                 Top = False, T200 = False, T1k = False, Median = False, 
                 humanTop = None, human200 = None, human1k = None, humanMedian = None,
                 AI = False, df_sample = df_parquet1, file_path = None, contest_num_for_eval = contest_num_for_eval,
                 descriptions = None, img = None, num_pairs = len(contest_num_for_eval),
                 num_eg = 600, random_seed = 42, apiKey = None):
        '''
        Overall: the evaluator compares the overall funniness of the group of ten model-generated captions against each group of ten contestant-submitted captions. 
        BestPick: the evaluator first pick the funniest caption from each of the two groups and then choose the funnier caption accordingly.
        Top, T200, T1k, Median: indicators of human submissions from different ranking levels
        humanTop, human200, human1k, humanMedian: groups of human contestant entries at different ranking levels 
        AI: False for our models, True for openAI
        file_path: caption file
        descriptions: descriptions corresponding to contest_num_for_eval
        img: img corresponding to contest_num_for_eval
        '''
        self.AI = AI
        self.testing = df_sample.sample(n = num_eg, random_state = random_seed, ignore_index=True)
        self.Overall = Overall
        self.BestPick = BestPick
        self.Top = Top
        self.T200 = T200
        self.T1k = T1k
        self.Median = Median
        self.human_captions_top = humanTop
        self.human_captions_200 = human200
        self.human_captions_1k = human1k
        self.human_captions_median = humanMedian
        self.filepath = file_path
        self.results = []
        self.apiKey = apiKey
        self.contest_num_for_eval = contest_num_for_eval
        self.descriptions = descriptions
        self.img = img
        self.num_pairs = num_pairs
        self.max_retries = 5  
        self.retry_delay = 2
        
        self.image_pairs = [] # for 5shot eg
        for i in range(num_eg):
            pair = []
            contest_num = self.testing['contest_number'][i]
            image_bytes = self.testing['image.bytes'][i]
            base64_image = base64.b64encode(image_bytes).decode()
            
            captions = self.testing['caption_choices'][i]
            captionA = str(captions[0])
            captionB = str(captions[1])
            label = str(self.testing['label'][i])
            
            pair.append(contest_num) #0
            pair.append(base64_image) #1
            pair.append(captionA) #2
            pair.append(captionB) #3
            pair.append(label) #4
            self.image_pairs.append(pair)
        
    def eval(self):
        '''
        Evaluation of captions generated by various language models
        '''
        # extract groups of ten captions
        if self.AI == False: # if captions are generated by our models
            model_df = pd.read_csv(self.filepath)
            test_set = model_df[model_df["info"] == "test"]
            val_set = model_df[model_df["info"] == "validation"]
            model_df = pd.concat([test_set, val_set], ignore_index=True)

            model_df = model_df[model_df['contest_number'].isin(self.contest_num_for_eval)]
            model_df = model_df.sort_values(by='contest_number', ascending=True, ignore_index=True) # same order as contest_num_for_eval
        
            model_captions = [] 
            for i in range(len(self.contest_num_for_eval)):
                group = ""
                for j in range(10):
                    if j == 0:
                        group += f"{j+1}.\n"
                        group += f"{model_df[f'caption{j+1}'][i]}"
                    else:
                        group += f"\n{j+1}.\n"
                        group += f"{model_df[f'caption{j+1}'][i]}"
                model_captions.append(group)
        else: # if captions are generated by OpenAI API
            gpt_df = pd.read_csv(self.filepath)
            gpt_df["contest_num"] = gpt_df['contest_num'].astype(int)
            gpt_df = gpt_df.sort_values(by='contest_num', ascending=True, ignore_index=True) # same order as contest_num_for_eval
            model_captions = []
            for i in range(len(self.contest_num_for_eval)):
                group = ""
                for j in range(10):
                    if j == 0:
                        group += f"{j+1}.\n"
                        group += f"{gpt_df[f'{j}'][i]}"
                    else:
                        group += f"\n{j+1}.\n"
                        group += f"{gpt_df[f'{j}'][i]}"
                model_captions.append(group)
                
        if self.Overall: # overall comparison
            client = OpenAI(api_key = self.apiKey)
            for i in tqdm(range(self.num_pairs)):
                #OpenAI API Key
                # print(i)
                # Getting the description
                d1 = self.testing["image_description"][i*6]
                dud1 = self.testing["image_uncanny_description"][i*6]

                d2 = self.testing["image_description"][i * 6 + 1]
                dud2 = self.testing["image_uncanny_description"][i * 6 + 1]

                d3 = self.testing["image_description"][i * 6 + 2]
                dud3 = self.testing["image_uncanny_description"][i * 6 + 2]

                d4 = self.testing["image_description"][i * 6 + 3]
                dud4 = self.testing["image_uncanny_description"][i * 6 +3]

                d5 = self.testing["image_description"][i * 6 + 4]
                dud5 = self.testing["image_uncanny_description"][i * 6 + 4]

                d6 = self.descriptions[i][0]
                dud6 = self.descriptions[i][1]

                #captions and label
                c1a = self.testing["caption_choices"][i * 6][0]
                c1b = self.testing["caption_choices"][i * 6][1]
                l1 = self.testing["label"][i * 6]

                c2a = self.testing["caption_choices"][i * 6 + 1][0]
                c2b = self.testing["caption_choices"][i * 6 + 1][1]
                l2 = self.testing["label"][i * 6 + 1]

                c3a = self.testing["caption_choices"][i * 6 + 2][0]
                c3b = self.testing["caption_choices"][i * 6 + 2][1]
                l3 = self.testing["label"][i * 6 + 2]

                c4a = self.testing["caption_choices"][i * 6 + 3][0]
                c4b = self.testing["caption_choices"][i * 6 + 3][1]
                l4 = self.testing["label"][i * 6 + 3]

                c5a = self.testing["caption_choices"][i * 6 + 4][0]
                c5b = self.testing["caption_choices"][i * 6 + 4][1]
                l5 = self.testing["label"][i * 6 + 4]

                c6a = model_captions[i]
                if self.Top:
                    c6b = self.human_captions_top[i]
                elif self.T200:
                    c6b = self.human_captions_200[i]
                elif self.T1k:
                    c6b = self.human_captions_1k[i]
                elif self.Median:
                    c6b = self.human_captions_median[i]
                    
                label = "A"
                flip_label = "B"

                response = client.chat.completions.create(
                model = "gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "You are a judge for the new yorker cartoon caption contest."},
                    {"role": "user", "content": "In this task, you will see two description for a cartoon. Then, you will see two captions that were written about the cartoon. Then you will choose which captions is funnier. I am going to give you five examples first and you answer the last example with either A or B"},
                    {"role": "user", "content": "For example, the descriptions for the images are " + d1 + " and " + dud1 + " The two captions are A: " + c1a + " B: " + c1b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l1},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d2 + " and " + dud2 + " The two captions are A: " + c2a + " B: " + c2b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l2},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d3 + " and " + dud3 + " The two captions are A: " + c3a + " B: " + c3b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l3},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d4 + " and " + dud4 + " The two captions are A: " + c4a + " B: " + c4b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l4},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d5 + " and " + dud5 + " The two captions are A: " + c5a + " B: " + c5b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l5},
                    {"role": "user", "content": "The descriptions for the images are " + d6 + " and " + dud6 + " The two groups of captions are group A: " + c6a + "\ngroup B: " + c6b },
                    {"role": "user", "content": "Choose the group of captions that is funnier. Answer with only one letter A or B, and nothing else."}
                ],
                logprobs = True,
                top_logprobs = 2,
                temperature = 0
                )
                
                if response.choices[0].message.content[-1] != "A" and response.choices[0].message.content[-1] != "B":
                    self.results.append([label, response.choices[0].message.content, response.choices[0].logprobs.content[0].top_logprobs])
                else:
                    self.results.append([label, response.choices[0].message.content[-1], response.choices[0].logprobs.content[0].top_logprobs])

                # flip the two groups to recalibrate the overall predictions later
                
                response = client.chat.completions.create(
                model = "gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "You are a judge for the new yorker cartoon caption contest."},
                    {"role": "user", "content": "In this task, you will see two description for a cartoon. Then, you will see two captions that were written about the cartoon. Then you will choose which captions is funnier. I am going to give you five examples first and you answer the last example with either A or B"},
                    {"role": "user", "content": "For example, the descriptions for the images are " + d1 + " and " + dud1 + " The two captions are A: " + c1a + " B: " + c1b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l1},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d2 + " and " + dud2 + " The two captions are A: " + c2a + " B: " + c2b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l2},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d3 + " and " + dud3 + " The two captions are A: " + c3a + " B: " + c3b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l3},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d4 + " and " + dud4 + " The two captions are A: " + c4a + " B: " + c4b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l4},
                    {"role": "user", "content": "Another example, the descriptions for the images are " + d5 + " and " + dud5 + " The two captions are A: " + c5a + " B: " + c5b},
                    {"role": "assistant", "content": "The caption that is funnier is " + l5},
                    {"role": "user", "content": "The descriptions for the images are " + d6 + " and " + dud6 + " The two groups of captions are group A: " + c6b + "\ngroup B: " + c6a },
                    {"role": "user", "content": "Choose the group of captions that is funnier. Answer with only one letter A or B, and nothing else."}
                ],
                logprobs = True,
                top_logprobs = 2,
                temperature = 0
                )
                if response.choices[0].message.content[-1] != "A" and response.choices[0].message.content[-1] != "B":
                    self.results.append([flip_label, response.choices[0].message.content, response.choices[0].logprobs.content[0].top_logprobs])
                else:
                    self.results.append([flip_label, response.choices[0].message.content[-1], response.choices[0].logprobs.content[0].top_logprobs])
                    
            return recalibrate(self.results)

        elif self.BestPick: # best pick comparison
            for i in tqdm(range(self.num_pairs)):
                base64_image1 = self.image_pairs[i*6][1]
                captionA1 = self.image_pairs[i*6][2]
                captionB1 = self.image_pairs[i*6][3]
                label1 = self.image_pairs[i*6][4]

                base64_image2 = self.image_pairs[i*6+1][1]
                captionA2 = self.image_pairs[i*6+1][2]
                captionB2 = self.image_pairs[i*6+1][3]
                label2 = self.image_pairs[i*6+1][4]

                base64_image3 = self.image_pairs[i*6+2][1]
                captionA3 = self.image_pairs[i*6+2][2]
                captionB3 = self.image_pairs[i*6+2][3]
                label3 = self.image_pairs[i*6+2][4]

                base64_image4 = self.image_pairs[i*6+3][1]
                captionA4 = self.image_pairs[i*6+3][2]
                captionB4 = self.image_pairs[i*6+3][3]
                label4 = self.image_pairs[i*6+3][4]

                base64_image5 = self.image_pairs[i*6+4][1]
                captionA5 = self.image_pairs[i*6+4][2]
                captionB5 = self.image_pairs[i*6+4][3]
                label5 = self.image_pairs[i*6+4][4]

                base64_image = self.img[i]
                captionA = model_captions[i]
                if self.Top:
                    captionB = self.human_captions_top[i]
                elif self.T200:
                    captionB = self.human_captions_200[i]
                elif self.T1k:
                    captionB = self.human_captions_1k[i]
                elif self.Median:
                    captionB = self.human_captions_median[i]
                
                label = "A"

                headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.apiKey}"
                }

                retry_count = 0 
                success = False
                while not success and retry_count < self.max_retries:
                    try:
                        payload = {
                        "model": "gpt-4o",
                        "messages": [
                            {"role": "system", 
                            "content": "You are a judge for the new yorker cartoon caption contest. Your job is to find the funniest caption."
                            },
                            # 1st example
                            {"role": "user",
                            "content": [
                                {"type": "text", 
                                "text": "In this task, you will see a cartoon first and two captions that were written about it then. The task is to choose which caption is funnier. I am going to show you five cartoons, corresponding captions and their answers first. In the end, for the last cartoon, answer with only one letter A or B, and nothing else."
                                },        
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image1}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"For this example, the two captions are A: {captionA1}, B: {captionB1}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label1}"},
                            # 2nd example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image2}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA2}, B: {captionB2}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label2}"},
                            # 3rd example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image3}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA3}, B: {captionB3}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label3}"},
                            # 4 example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image4}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA4}, B: {captionB4}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label4}"},
                            # 5 example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image5}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA5}, B: {captionB5}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label5}"},


                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Find the funniest caption for each group. Then choose the funnier group based on these funniest captions. Think step by step but finish the last line of your answer with only one letter A or B, and nothing else. A: {captionA} or B: {captionB}"
                                }],
                            }
                        ],

                        "logprobs": True,
                        "top_logprobs": 2,
                        "temperature": 0
                        }

                        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
                        if 'choices' in response.json():
                            self.results.append([label, response.json()['choices'][0]['message']['content'], response.json()['choices'][0]['logprobs']['content'][0]['top_logprobs']])
                            success = True
                        else: 
                            print("No 'choices' in response, retrying...")
                            raise KeyError("The 'choices' key is missing or empty.")

                    except KeyError as key_err:
                        print(f'Key error: {key_err}')
                    except Exception as err:
                        print(f'Other error occurred: {err}')

                    if not success:
                        retry_count += 1
                        print(f"Attempt {retry_count} failed for iteration {i}, retrying in {self.retry_delay} seconds...")
                        time.sleep(self.retry_delay)

                if not success:
                    print(f"Max retries reached for iteration {i}. Moving to next iteration.")

                flip_label = "B" 

                retry_count = 0 
                success = False
                while not success and retry_count < self.max_retries:
                    try:
                        payload = {
                        "model": "gpt-4o",
                        "messages": [
                            {"role": "system", 
                            "content": "You are a judge for the new yorker cartoon caption contest. Your job is to find the funniest caption."
                            },
                            # 1st example
                            {"role": "user",
                            "content": [
                                {"type": "text", 
                                "text": "In this task, you will see a cartoon first and two captions that were written about it then. The task is to choose which caption is funnier. I am going to show you five cartoons, corresponding captions and their answers first. In the end, for the last cartoon, answer with only one letter A or B, and nothing else."
                                },        
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image1}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"For this example, the two captions are A: {captionA1}, B: {captionB1}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label1}"},
                            # 2nd example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image2}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA2}, B: {captionB2}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label2}"},
                            # 3rd example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image3}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA3}, B: {captionB3}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label3}"},
                            # 4 example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image4}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA4}, B: {captionB4}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label4}"},
                            # 5 example
                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image5}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Another example, the two captions are A: {captionA5}, B: {captionB5}. The answer is"
                                }
                            ]},
                            {"role": "assistant", 
                            "content": f"{label5}"},


                            {"role": "user",
                            "content": [
                                {"type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}",  "detail": "high"}
                                },
                                {"type": "text",
                                "text": f"Find the funniest caption for each group. Then choose the funnier group based on these funniest captions. Think step by step but finish the last line of your answer with only one letter A or B, and nothing else. A: {captionB} or B: {captionA}"
                                }],
                            }
                        ],

                        "logprobs": True,
                        "top_logprobs": 2,
                        "temperature": 0
                        }

                        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
                        if 'choices' in response.json():
                            self.results.append([flip_label, response.json()['choices'][0]['message']['content'], response.json()['choices'][0]['logprobs']['content'][0]['top_logprobs']])
                            success = True
                        else: 
                            print("No 'choices' in response, retrying...")
                            raise KeyError("The 'choices' key is missing or empty.")

                    except KeyError as key_err:
                        print(f'Key error: {key_err}')
                    except Exception as err:
                        print(f'Other error occurred: {err}')

                    if not success:
                        retry_count += 1
                        print(f"Attempt {retry_count} failed for iteration {i}, retrying in {self.retry_delay} seconds...")
                        time.sleep(self.retry_delay)

                if not success:
                    print(f"Max retries reached for iteration {i}. Moving to next iteration.")
                    
            return compute_accuracy(self.results)
                    
            
                
            
                    
