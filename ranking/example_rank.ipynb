{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6887cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenjiayi/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/chenjiayi/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from rank import compute_accuracy, recalibrate, recalibrate_v, prepare_DescriptionModel, prepare_VisionModel, Ranking\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de415466",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"Your OpenAI API Key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6457fc",
   "metadata": {},
   "source": [
    "## Pairwise Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e8add",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4turbo, Description: Hessel's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56eab11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testing = prepare_DescriptionModel(comparison_method = \"Pairwise\", Hessel = True)\n",
    "model = Ranking(comparison_method = \"Pairwise\", evaluator = \"gpt-4-turbo\", annotation_type = \"Description\",\n",
    "                  description_generator = \"Hessel\", testing = testing, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7420d16",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4oV, Raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6b265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_pairs = prepare_VisionModel(comparison_method = \"Pairwise\")\n",
    "model = Ranking(comparison_method = \"Pairwise\", evaluator = \"gpt-4o\", annotation_type = \"Image\",\n",
    "                 image_pairs = image_pairs, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebedabbc",
   "metadata": {},
   "source": [
    "## Overall Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a57ea",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4turbo, Description Generator: gpt4V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35ad0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/chenjiayi/Desktop/David_generated'\n",
    "\n",
    "Dtesting = pd.DataFrame(columns=['cnum', 'canny', 'uncanny']) # description df for 100 testing cartoons\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename != \".DS_Store\":\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        Dtesting = pd.concat([Dtesting, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01541ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/chenjiayi/Desktop/gpt4V_description/example.csv'\n",
    "Deg1 = pd.read_csv(file_path)\n",
    "file_path = '/Users/chenjiayi/Desktop/gpt4V_description/example_new.csv'\n",
    "Deg2 = pd.read_csv(file_path)\n",
    "Deg = pd.concat([Deg1, Deg2], ignore_index=True)\n",
    "\n",
    "deg, eg, dtesting, captions = prepare_DescriptionModel(comparison_method = \"Overall\", GPT4V = True, \n",
    "                                                       Deg = Deg, Dtesting = Dtesting)\n",
    "\n",
    "model = Ranking(comparison_method = \"Overall\", evaluator = \"gpt-4-turbo\", annotation_type = \"Description\",\n",
    "                description_generator = \"gpt-4-vision\", deg = deg, dtesting = dtesting, eg = eg,\n",
    "                captions = captions, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f134213",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4turbo-V, Raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3e77c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:11<00:00, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/chenjiayi/Desktop/humor/cartoon_forGroupComparison.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    cartoons_v = pickle.load(file)\n",
    "    \n",
    "image_pairs, img, captions = prepare_VisionModel(comparison_method = \"Overall\", \n",
    "                                                 cartoons_GroupComparison = cartoons_v)\n",
    "\n",
    "model = Ranking(comparison_method = \"Overall\", evaluator = \"gpt-4-turbo\", annotation_type = \"Image\",\n",
    "                 image_pairs = image_pairs, img = img, captions = captions, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d051e12",
   "metadata": {},
   "source": [
    "## Best Pick Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396a1dc",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4turbo, Description Generator: gpt4oV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9721822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/chenjiayi/Desktop/gpt4oV_description/example_o.csv'\n",
    "Deg1 = pd.read_csv(file_path)\n",
    "file_path = '/Users/chenjiayi/Desktop/gpt4oV_description/new_example_o.csv'\n",
    "Deg2 = pd.read_csv(file_path)\n",
    "Deg = pd.concat([Deg1, Deg2], ignore_index=True)\n",
    "    \n",
    "deg, eg, dtesting, captions = prepare_DescriptionModel(comparison_method = \"BestPick\", GPT4oV = True, \n",
    "                                                       Deg = Deg, Dtesting = Dtesting)\n",
    " \n",
    "model = Ranking(comparison_method = \"BestPick\", evaluator = \"gpt-4-turbo\", annotation_type = \"Description\",\n",
    "                description_generator = \"gpt-4o-vision\", deg = deg, dtesting = dtesting, eg = eg,\n",
    "                captions = captions, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71036d9",
   "metadata": {},
   "source": [
    "### Evaluator: gpt4oV, Raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ac18fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_pairs, img, captions = prepare_VisionModel(comparison_method = \"Overall\", \n",
    "                                                 cartoons_GroupComparison = cartoons_v)\n",
    "\n",
    "model = Ranking(comparison_method = \"BestPick\", evaluator = \"gpt-4o\", annotation_type = \"Image\",\n",
    "                 image_pairs = image_pairs, img = img, captions = captions, apiKey = api_key, num_pairs = 1)\n",
    "accuracy = model.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7175e97",
   "metadata": {},
   "source": [
    "## Overall Comparison with evaluator gpt4turbo and gpt4V-generated description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da11da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [02:35<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of results is 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/chenjiayi/Desktop/gpt4V_description/example.csv'\n",
    "Deg1 = pd.read_csv(file_path)\n",
    "file_path = '/Users/chenjiayi/Desktop/gpt4V_description/example_new.csv'\n",
    "Deg2 = pd.read_csv(file_path)\n",
    "Deg = pd.concat([Deg1, Deg2], ignore_index=True)\n",
    "\n",
    "deg, eg, dtesting, captions = prepare_DescriptionModel(comparison_method = \"Overall\", GPT4V = True, \n",
    "                                                       Deg = Deg, Dtesting = Dtesting)\n",
    "\n",
    "model = Ranking(comparison_method = \"Overall\", evaluator = \"gpt-4-turbo\", annotation_type = \"Description\",\n",
    "                description_generator = \"gpt-4-vision\", deg = deg, dtesting = dtesting, eg = eg,\n",
    "                captions = captions, apiKey = api_key)\n",
    "accuracy = model.rank()\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
